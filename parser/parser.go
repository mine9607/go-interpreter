package parser

import (
	"fmt"
	"monkey/ast"
	"monkey/lexer"
	"monkey/token"
	"strconv"
)

// define precedences

var precedences = map[token.TokenType]int{
	token.EQ:           EQUALS,
	token.NOT_EQ:       EQUALS,
	token.LT:           LESSGREATER,
	token.GT:           LESSGREATER,
	token.PLUS:         SUM,
	token.MINUS:        SUM,
	token.INCR:         SUM, // ++x
	token.DECR:         SUM, // --x
	token.SLASH:        PRODUCT,
	token.STAR:         PRODUCT,
	token.EXP:          EXPONENT,
	token.ADD_ASSIGN:   ASSIGN, // x += 2
	token.MINUS_ASSIGN: ASSIGN, // x -= 2
}

// Setting const to use for Operator Precedence: Remember PEMDAS

const (
	_ int = iota
	LOWEST
	ASSIGN      // = or += or -=
	EQUALS      // == or !=
	LESSGREATER // > or <
	SUM         // + or - or ++x or --x
	PRODUCT     // * or /
	EXPONENT    // **
	PREFIX      // -X or !X or ++X or --X
	CALL        // myFunction(X)
)

// Note curToken and peekToken act like the lexer pointers "position" and "readPosition" but instead of pointing to input chars they point to the token struct generated by those chars
type Parser struct {
	l              *lexer.Lexer // pointer to an instance of the lexer
	curToken       token.Token  // current Token ~ lexer "position"
	peekToken      token.Token  // peek Token ~ lexer "readPosition"
	errors         []string
	prefixParseFns map[token.TokenType]prefixParseFn
	infixParseFns  map[token.TokenType]infixParseFn
}

// func to initialize an instance of a Parser - accepts a lexer instance and returns a pointer to a parser instance
// the function accepts a lexer and sets the Parer's lexer property = the lexer
// p.nextToken() is called to advance the lexer and tokens 2 chars from their initial position
// so that they line up with the first and second chars of the input and first and second tokens from the lexer respectively
func New(l *lexer.Lexer) *Parser {
	p := &Parser{
		l:      l,
		errors: []string{},
	}

	// Initialize the prefixParseFns map and register a parsing function
	p.prefixParseFns = make(map[token.TokenType]prefixParseFn)
	p.registerPrefix(token.IDENT, p.parseIdentifier)
	p.registerPrefix(token.INT, p.parseIntegerLiteral)
	p.registerPrefix(token.BANG, p.parsePrefixExpression)
	p.registerPrefix(token.MINUS, p.parsePrefixExpression)
	p.registerPrefix(token.INCR, p.parsePrefixExpression)
	p.registerPrefix(token.DECR, p.parsePrefixExpression)

	p.infixParseFns = make(map[token.TokenType]infixParseFn)
	p.registerInfix(token.PLUS, p.parseInfixExpression)
	p.registerInfix(token.MINUS, p.parseInfixExpression)
	p.registerInfix(token.SLASH, p.parseInfixExpression)
	p.registerInfix(token.STAR, p.parseInfixExpression)
	p.registerInfix(token.EQ, p.parseInfixExpression)
	p.registerInfix(token.NOT_EQ, p.parseInfixExpression)
	p.registerInfix(token.LT, p.parseInfixExpression)
	p.registerInfix(token.GT, p.parseInfixExpression)
	p.registerInfix(token.EXP, p.parseInfixExpression)
	p.registerInfix(token.ADD_ASSIGN, p.parseInfixExpression)
	p.registerInfix(token.MINUS_ASSIGN, p.parseInfixExpression)

	// read two tokens, so curToken and peekToken are both set
	p.nextToken()
	p.nextToken()
	return p
}

func (p *Parser) parseIdentifier() ast.Expression {
	return &ast.Identifier{Token: p.curToken, Value: p.curToken.Literal}
}

func (p *Parser) Errors() []string {
	return p.errors
}

func (p *Parser) peekError(t token.TokenType) {
	msg := fmt.Sprintf("expected next token to be %s, got %s insted", t, p.peekToken.Type)
	p.errors = append(p.errors, msg)
}

// parser helper function to advance the current and peek tokens
func (p *Parser) nextToken() {
	p.curToken = p.peekToken
	p.peekToken = p.l.NextToken()
}

// helper functions below
func (p *Parser) curTokenIs(t token.TokenType) bool {
	return p.curToken.Type == t
}

func (p *Parser) peekTokenIs(t token.TokenType) bool {
	return p.peekToken.Type == t
}

// ** This is an ASSERTION FUNCTION common to most parsers **
// Its purpose is to enforce the correctness of the order of tokens by checking the type of the next token
// It looks at the next token and only if it is the expected next token is p.nextToken does it call nextToken
func (p *Parser) expectPeek(t token.TokenType) bool {
	if p.peekTokenIs(t) {
		p.nextToken()
		return true
	} else {
		p.peekError(t)
		return false
	}
}

// THIS IS THE PARSING LOGIC FOR THE PROGRAM
func (p *Parser) ParseProgram() *ast.Program {
	program := &ast.Program{}
	program.Statements = []ast.Statement{}

	for !p.curTokenIs(token.EOF) {
		stmt := p.parseStatement()
		if stmt != nil {
			program.Statements = append(program.Statements, stmt)
		}
		p.nextToken()
	}
	return program
}

func (p *Parser) parseStatement() ast.Statement {
	switch p.curToken.Type {
	case token.LET:
		return p.parseLetStatement()
	case token.RETURN:
		return p.parseReturnStatement()
	default:
		return p.parseExpressionStatement()
	}
}

func (p *Parser) parseLetStatement() *ast.LetStatement {
	stmt := &ast.LetStatement{Token: p.curToken}

	if !p.expectPeek(token.IDENT) {
		return nil
	}

	stmt.Name = &ast.Identifier{Token: p.curToken, Value: p.curToken.Literal}

	if !p.expectPeek(token.ASSIGN) {
		return nil
	}

	// TODO: Skip the expressions until we encounter a semi-colon

	for !p.curTokenIs(token.SEMICOLON) {
		p.nextToken()
	}

	return stmt
}

func (p *Parser) parseReturnStatement() *ast.ReturnStatement {
	stmt := &ast.ReturnStatement{Token: p.curToken}

	p.nextToken()

	// TODO: skip the expressions until we encounter a semi-colon

	for !p.curTokenIs(token.SEMICOLON) {
		p.nextToken()
	}

	return stmt
}

// Note: here we are defining function types to use in function calling to limit which types of funcs a higher-order function can accept as arguments.

// Defining function types defines the function signature
// EXAMPLE of TYPE: type prefixParseFn func() ast.Expression
// EXAMPLE of DEFINITION: func prefixParseFn () ast.Expression {}
type (
	prefixParseFn func() ast.Expression
	infixParseFn  func(ast.Expression) ast.Expression
)

// Note: the prefixParseFn gets called when our Parser encounters an expression token type in "prefix" position
// Note: the infixParseFn gets called when our Parser encounters an expression token in the "infix" position
// Note: the argument that an infixParseFn takes will be the "left side" of the infix operator being parsed

// Helper functions to add a prefix or infix parse function to the map properties in the Parser struct
func (p *Parser) registerPrefix(tokenType token.TokenType, fn prefixParseFn) {
	p.prefixParseFns[tokenType] = fn
}

func (p *Parser) registerInfix(tokenType token.TokenType, fn infixParseFn) {
	p.infixParseFns[tokenType] = fn
}

func (p *Parser) noPrefixParseFnError(t token.TokenType) {
	msg := fmt.Sprintf("no prefix parse function for %s found", t)
	p.errors = append(p.errors, msg)
}

func (p *Parser) parseExpressionStatement() *ast.ExpressionStatement {
	stmt := &ast.ExpressionStatement{Token: p.curToken}
	stmt.Expression = p.parseExpression(LOWEST)

	if p.peekTokenIs(token.SEMICOLON) {
		p.nextToken()
	}
	return stmt
}

func (p *Parser) parseExpression(precedence int) ast.Expression {
	// check if we have a parsing function associated with the current Token p.curToken.Type in the prefix position
	prefix := p.prefixParseFns[p.curToken.Type]
	if prefix == nil {
		p.noPrefixParseFnError(p.curToken.Type)
		return nil
	}
	leftExp := prefix()

	for !p.peekTokenIs(token.SEMICOLON) && precedence < p.peekPrecedence() {
		infix := p.infixParseFns[p.peekToken.Type]
		if infix == nil {
			return leftExp
		}

		p.nextToken()

		leftExp = infix(leftExp)
	}
	return leftExp

}

func (p *Parser) parseIntegerLiteral() ast.Expression {
	lit := &ast.IntegerLiteral{Token: p.curToken}

	value, err := strconv.ParseInt(p.curToken.Literal, 0, 64)
	if err != nil {
		msg := fmt.Sprintf("could not parse %q as integer", p.curToken.Literal)
		p.errors = append(p.errors, msg)
		return nil
	}

	lit.Value = value

	return lit
}

func (p *Parser) parsePrefixExpression() ast.Expression {
	expression := &ast.PrefixExpression{
		Token:    p.curToken,
		Operator: p.curToken.Literal,
	}

	// WARNING: LANG only supports ! and -

	// NOTE: we may run into trouble here since we have some double token prefix tokens (++, --, +=, -=)
	// We may need additional  logic to call p.nextToken() a second time or implement a peek variable
	// to determine if we need to call p.nextToken once or twice to read the expression
	p.nextToken()

	expression.Right = p.parseExpression(PREFIX)

	return expression
}

// returns the precedence associated with the token type of p.peekToken
// if it doesn't find a precedence for p.peekToken it defaults to LOWEST
func (p *Parser) peekPrecedence() int {
	if p, ok := precedences[p.peekToken.Type]; ok {
		return p
	}
	return LOWEST
}

func (p *Parser) curPrecedence() int {
	if p, ok := precedences[p.curToken.Type]; ok {
		return p
	}
	return LOWEST
}

func (p *Parser) parseInfixExpression(left ast.Expression) ast.Expression {
	expression := &ast.InfixExpression{
		Token:    p.curToken,
		Operator: p.curToken.Literal,
		Left:     left,
	}

	precedence := p.curPrecedence()
	p.nextToken() // NOTE: need logic here for case of +=, -= and **
	expression.Right = p.parseExpression(precedence)

	return expression
}
